{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## importing necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## importing the cleaned data\n",
    "df=pd.read_csv('final_df.csv',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>customer_no</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_11</th>\n",
       "      <th>feature_50</th>\n",
       "      <th>feature_55</th>\n",
       "      <th>feature_59</th>\n",
       "      <th>feature_62</th>\n",
       "      <th>feature_68</th>\n",
       "      <th>feature_78</th>\n",
       "      <th>Bad_label</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>owner_indic</th>\n",
       "      <th>no_of_accts</th>\n",
       "      <th>acct_type</th>\n",
       "      <th>utilization</th>\n",
       "      <th>utilization_count</th>\n",
       "      <th>cur_balance_amt</th>\n",
       "      <th>enquiry_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>650.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>325490</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>650.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1754678</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>650.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>650.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>650.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2634689</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  customer_no  feature_1  feature_3  feature_4  feature_11  \\\n",
       "0           0            1          1      650.0        2.0           1   \n",
       "1           1            1          1      650.0        2.0           1   \n",
       "2           2            1          1      650.0        2.0           1   \n",
       "3           3            1          1      650.0        2.0           1   \n",
       "4           4            1          1      650.0        2.0           1   \n",
       "\n",
       "   feature_50  feature_55  feature_59  feature_62  feature_68  feature_78  \\\n",
       "0           1         1.0           1           1         2.0         1.0   \n",
       "1           1         1.0           1           1         2.0         1.0   \n",
       "2           1         1.0           1           1         2.0         1.0   \n",
       "3           1         1.0           1           1         2.0         1.0   \n",
       "4           1         1.0           1           1         2.0         1.0   \n",
       "\n",
       "   Bad_label  Unnamed: 0.1  owner_indic  no_of_accts  acct_type  utilization  \\\n",
       "0          0             0            1           17          2            2   \n",
       "1          0             1            4            1          2            2   \n",
       "2          0             2            1           17          5            2   \n",
       "3          0             3            1           17          5            0   \n",
       "4          0             4            1           17         10            2   \n",
       "\n",
       "   utilization_count  cur_balance_amt  enquiry_count  \n",
       "0                  3           325490              1  \n",
       "1                  1          1754678              1  \n",
       "2                  1                0              1  \n",
       "3                  2                0              1  \n",
       "4                  6          2634689             14  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns',None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[['customer_no', 'feature_1', 'feature_3', 'feature_4',\n",
    "       'feature_11', 'feature_50', 'feature_55', 'feature_59', 'feature_62',\n",
    "       'feature_68', 'feature_78', 'owner_indic',\n",
    "       'no_of_accts', 'acct_type', 'utilization',\n",
    "       'cur_balance_amt', 'enquiry_count', 'Bad_label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking class balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    69962\n",
       "1     2969\n",
       "Name: Bad_label, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Bad_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41185    0\n",
       "14623    0\n",
       "34341    0\n",
       "50574    0\n",
       "9956     0\n",
       "        ..\n",
       "69105    0\n",
       "21482    0\n",
       "19168    0\n",
       "69845    0\n",
       "35318    0\n",
       "Name: Bad_label, Length: 54698, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before OverSampling, counts of label '1': 2258\n",
      "Before OverSampling, counts of label '0': 52440 \n",
      "\n",
      "After OverSampling, the shape of train_X: (104880, 16)\n",
      "After OverSampling, the shape of train_y: (104880,) \n",
      "\n",
      "After OverSampling, counts of label '1': 52440\n",
      "After OverSampling, counts of label '0': 52440\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train == 1))) \n",
    "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train == 0)))\n",
    "sm = SMOTE(random_state = 2) \n",
    "X_res, y_res = sm.fit_sample(X_train,y_train) \n",
    "  \n",
    "print('After OverSampling, the shape of train_X: {}'.format(X_res.shape)) \n",
    "print('After OverSampling, the shape of train_y: {} \\n'.format(y_res.shape)) \n",
    "  \n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_res == 1))) \n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_res == 0))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X=df.iloc[:,1:17]\n",
    "y=df.Bad_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LR=LogisticRegression()\n",
    "model=LR.fit(X_res,y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "score=roc_auc_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47841797935281427"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT=DecisionTreeClassifier()\n",
    "model=DT.fit(X_res,y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pr=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5553641853445046"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score=roc_auc_score(y_test,y_pr)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RF=RandomForestClassifier()\n",
    "model=RF.fit(X_train,y_train)\n",
    "y_pre=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5481283422459893"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score=roc_auc_score(y_test,y_pre)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoosting Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ab=AdaBoostClassifier(n_estimators=50,learning_rate=0.1)\n",
    "model=ab.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_pre=model.predict(X_test)\n",
    "score=roc_auc_score(y_test,y_pre)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,LeakyReLU,PReLU,ELU,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_11</th>\n",
       "      <th>feature_50</th>\n",
       "      <th>feature_55</th>\n",
       "      <th>feature_59</th>\n",
       "      <th>feature_62</th>\n",
       "      <th>feature_68</th>\n",
       "      <th>feature_78</th>\n",
       "      <th>owner_indic</th>\n",
       "      <th>no_of_accts</th>\n",
       "      <th>acct_type</th>\n",
       "      <th>utilization</th>\n",
       "      <th>cur_balance_amt</th>\n",
       "      <th>enquiry_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>786.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2226154</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>760.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>272943</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>708.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>12144</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>754.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>781149</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>745.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>196599</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_3  feature_4  feature_11  feature_50  feature_55  \\\n",
       "0          3      786.0        1.0           1           0         1.0   \n",
       "1          3      760.0        3.0           1           0         1.0   \n",
       "2          6      708.0        3.0           1           1         1.0   \n",
       "3          4      754.0        1.0           1           0         1.0   \n",
       "4          4      745.0        3.0           1           0         1.0   \n",
       "\n",
       "   feature_59  feature_62  feature_68  feature_78  owner_indic  no_of_accts  \\\n",
       "0           1           1         1.0         1.0            1           22   \n",
       "1           1           1         1.0         1.0            1            8   \n",
       "2           1           1         2.0         1.0            1           15   \n",
       "3           1           1         1.0         1.0            1            4   \n",
       "4           1           1         1.0         1.0            1           15   \n",
       "\n",
       "   acct_type  utilization  cur_balance_amt  enquiry_count  \n",
       "0          2            2          2226154             12  \n",
       "1          1            2           272943              3  \n",
       "2         10            2            12144             25  \n",
       "3          2            2           781149              1  \n",
       "4         10            0           196599             17  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Shubhangi sakarkar\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 70269 samples, validate on 34611 samples\n",
      "Epoch 1/50\n",
      "70269/70269 [==============================] - 15s 211us/step - loss: 4.0913 - accuracy: 0.7457 - val_loss: 16.0807 - val_accuracy: 8.9567e-04\n",
      "Epoch 2/50\n",
      "70269/70269 [==============================] - 14s 204us/step - loss: 4.0838 - accuracy: 0.7458 - val_loss: 16.0921 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "70269/70269 [==============================] - 14s 202us/step - loss: 4.0814 - accuracy: 0.7459 - val_loss: 16.0732 - val_accuracy: 4.3339e-04\n",
      "Epoch 4/50\n",
      "70269/70269 [==============================] - 15s 210us/step - loss: 4.0786 - accuracy: 0.7459 - val_loss: 16.0426 - val_accuracy: 0.0013\n",
      "Epoch 5/50\n",
      "70269/70269 [==============================] - 15s 211us/step - loss: 4.0763 - accuracy: 0.7459 - val_loss: 16.0380 - val_accuracy: 0.0010\n",
      "Epoch 6/50\n",
      "70269/70269 [==============================] - 15s 207us/step - loss: 4.0755 - accuracy: 0.7459 - val_loss: 16.0466 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "70269/70269 [==============================] - 14s 202us/step - loss: 4.0749 - accuracy: 0.7459 - val_loss: 16.0261 - val_accuracy: 0.0055\n",
      "Epoch 8/50\n",
      "70269/70269 [==============================] - 15s 209us/step - loss: 4.0742 - accuracy: 0.7460 - val_loss: 16.0415 - val_accuracy: 6.0674e-04\n",
      "Epoch 9/50\n",
      "70269/70269 [==============================] - 14s 201us/step - loss: 4.0738 - accuracy: 0.7459 - val_loss: 16.0284 - val_accuracy: 0.0036\n",
      "Epoch 10/50\n",
      "70269/70269 [==============================] - 14s 203us/step - loss: 4.0743 - accuracy: 0.7458 - val_loss: 16.0293 - val_accuracy: 0.0023\n",
      "Epoch 11/50\n",
      "70269/70269 [==============================] - 14s 205us/step - loss: 4.0737 - accuracy: 0.7459 - val_loss: 16.0425 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "70269/70269 [==============================] - 15s 214us/step - loss: 4.0742 - accuracy: 0.7457 - val_loss: 16.0248 - val_accuracy: 0.0057\n",
      "Epoch 13/50\n",
      "70269/70269 [==============================] - 14s 205us/step - loss: 4.0735 - accuracy: 0.7458 - val_loss: 16.0348 - val_accuracy: 0.0011\n",
      "Epoch 14/50\n",
      "70269/70269 [==============================] - 14s 205us/step - loss: 4.0734 - accuracy: 0.7458 - val_loss: 16.0249 - val_accuracy: 0.0057\n",
      "Epoch 15/50\n",
      "70269/70269 [==============================] - 15s 211us/step - loss: 4.0738 - accuracy: 0.7458 - val_loss: 16.0460 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "70269/70269 [==============================] - 14s 204us/step - loss: 4.0736 - accuracy: 0.7457 - val_loss: 16.0432 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "70269/70269 [==============================] - 14s 205us/step - loss: 4.0729 - accuracy: 0.7460 - val_loss: 16.0401 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "70269/70269 [==============================] - 14s 206us/step - loss: 4.0730 - accuracy: 0.7459 - val_loss: 16.0257 - val_accuracy: 0.0053\n",
      "Epoch 19/50\n",
      "70269/70269 [==============================] - 15s 208us/step - loss: 4.0732 - accuracy: 0.7459 - val_loss: 16.0402 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "70269/70269 [==============================] - 15s 219us/step - loss: 4.0739 - accuracy: 0.7457 - val_loss: 16.0394 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "70269/70269 [==============================] - 14s 203us/step - loss: 4.0729 - accuracy: 0.7459 - val_loss: 16.0424 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "70269/70269 [==============================] - 14s 204us/step - loss: 4.0730 - accuracy: 0.7459 - val_loss: 16.0300 - val_accuracy: 0.0016\n",
      "Epoch 23/50\n",
      "70269/70269 [==============================] - 14s 204us/step - loss: 4.0733 - accuracy: 0.7459 - val_loss: 16.0309 - val_accuracy: 8.3788e-04\n",
      "Epoch 24/50\n",
      "70269/70269 [==============================] - 15s 211us/step - loss: 4.0734 - accuracy: 0.7459 - val_loss: 16.0288 - val_accuracy: 0.0025\n",
      "Epoch 25/50\n",
      "70269/70269 [==============================] - 14s 206us/step - loss: 4.0730 - accuracy: 0.7458 - val_loss: 16.0296 - val_accuracy: 0.0012\n",
      "Epoch 26/50\n",
      "70269/70269 [==============================] - 14s 205us/step - loss: 4.0728 - accuracy: 0.7458 - val_loss: 16.0294 - val_accuracy: 0.0014\n",
      "Epoch 27/50\n",
      "70269/70269 [==============================] - 15s 211us/step - loss: 4.0734 - accuracy: 0.7459 - val_loss: 16.0282 - val_accuracy: 0.0022\n",
      "Epoch 28/50\n",
      "70269/70269 [==============================] - 15s 208us/step - loss: 4.0731 - accuracy: 0.7459 - val_loss: 16.0362 - val_accuracy: 5.7785e-05\n",
      "Epoch 29/50\n",
      "70269/70269 [==============================] - 15s 209us/step - loss: 4.0732 - accuracy: 0.7458 - val_loss: 16.0450 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "70269/70269 [==============================] - 15s 207us/step - loss: 4.0728 - accuracy: 0.7460 - val_loss: 16.0324 - val_accuracy: 2.8893e-05\n",
      "Epoch 31/50\n",
      "70269/70269 [==============================] - 14s 205us/step - loss: 4.0731 - accuracy: 0.7459 - val_loss: 16.0341 - val_accuracy: 0.0011\n",
      "Epoch 32/50\n",
      "70269/70269 [==============================] - 15s 207us/step - loss: 4.0727 - accuracy: 0.7460 - val_loss: 16.0338 - val_accuracy: 0.0011\n",
      "Epoch 33/50\n",
      "70269/70269 [==============================] - 15s 213us/step - loss: 4.0729 - accuracy: 0.7459 - val_loss: 16.0252 - val_accuracy: 0.0057\n",
      "Epoch 34/50\n",
      "70269/70269 [==============================] - 14s 196us/step - loss: 4.0731 - accuracy: 0.7460 - val_loss: 16.0314 - val_accuracy: 0.0012\n",
      "Epoch 35/50\n",
      "70269/70269 [==============================] - 14s 197us/step - loss: 4.0724 - accuracy: 0.7461 - val_loss: 16.0239 - val_accuracy: 0.0058\n",
      "Epoch 36/50\n",
      "70269/70269 [==============================] - 14s 196us/step - loss: 4.0727 - accuracy: 0.7459 - val_loss: 16.0646 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "70269/70269 [==============================] - 14s 203us/step - loss: 4.0730 - accuracy: 0.7458 - val_loss: 16.0259 - val_accuracy: 0.0044\n",
      "Epoch 38/50\n",
      "70269/70269 [==============================] - 16s 223us/step - loss: 4.0728 - accuracy: 0.7458 - val_loss: 16.0248 - val_accuracy: 0.0058\n",
      "Epoch 39/50\n",
      "70269/70269 [==============================] - 17s 242us/step - loss: 4.0728 - accuracy: 0.7460 - val_loss: 16.0492 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "70269/70269 [==============================] - 19s 263us/step - loss: 4.0728 - accuracy: 0.7460 - val_loss: 16.0452 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "70269/70269 [==============================] - 20s 279us/step - loss: 4.0727 - accuracy: 0.7459 - val_loss: 16.0414 - val_accuracy: 2.6003e-04\n",
      "Epoch 42/50\n",
      "70269/70269 [==============================] - 19s 265us/step - loss: 4.0725 - accuracy: 0.7459 - val_loss: 16.0460 - val_accuracy: 2.0225e-04\n",
      "Epoch 43/50\n",
      "70269/70269 [==============================] - 14s 205us/step - loss: 4.0722 - accuracy: 0.7460 - val_loss: 16.0432 - val_accuracy: 8.6678e-05\n",
      "Epoch 44/50\n",
      "70269/70269 [==============================] - 17s 240us/step - loss: 4.0725 - accuracy: 0.7460 - val_loss: 16.0278 - val_accuracy: 0.0034\n",
      "Epoch 45/50\n",
      "70269/70269 [==============================] - 16s 228us/step - loss: 4.0725 - accuracy: 0.7459 - val_loss: 16.0470 - val_accuracy: 2.3114e-04\n",
      "Epoch 46/50\n",
      "70269/70269 [==============================] - 16s 228us/step - loss: 4.0728 - accuracy: 0.7460 - val_loss: 16.0240 - val_accuracy: 0.0058\n",
      "Epoch 47/50\n",
      "70269/70269 [==============================] - 17s 241us/step - loss: 4.0727 - accuracy: 0.7459 - val_loss: 16.0304 - val_accuracy: 0.0016\n",
      "Epoch 48/50\n",
      "70269/70269 [==============================] - 18s 260us/step - loss: 4.0727 - accuracy: 0.7460 - val_loss: 16.0258 - val_accuracy: 0.0052\n",
      "Epoch 49/50\n",
      "70269/70269 [==============================] - 17s 235us/step - loss: 4.0727 - accuracy: 0.7459 - val_loss: 16.0302 - val_accuracy: 0.0017\n",
      "Epoch 50/50\n",
      "70269/70269 [==============================] - 16s 229us/step - loss: 4.0725 - accuracy: 0.7459 - val_loss: 16.0235 - val_accuracy: 0.0058\n"
     ]
    }
   ],
   "source": [
    "##initilaizing ANN\"\n",
    "classifier=Sequential()\n",
    "\n",
    "##creating input and 1 hidden layer\"\n",
    "classifier.add(Dense(units=6, input_dim=16,kernel_initializer='he_uniform',activation='relu'))\n",
    "\n",
    "##adding second hidden layer\"\n",
    "classifier.add(Dense(units=6,kernel_initializer='he_uniform',activation='relu'))\n",
    "\n",
    "##adding output layer\"\n",
    "classifier.add(Dense(units=1,kernel_initializer='glorot_uniform',activation='sigmoid'))\n",
    "\n",
    "\n",
    "##compling ANN\"\n",
    "classifier.compile(optimizer='Adamax',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "##fitting ANN to training set\"\n",
    "model_history=classifier.fit(X_res,y_res,batch_size=10,validation_split=0.33,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(model_history.history['loss'])\n",
    "plt.plot(model_history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9571107332858004"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making the predictions and evaluating the model\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Calculate the Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "score=accuracy_score(y_pred,y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
